{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from typing import Dict, Any, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "\n",
    "# Configuration\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "PLOT_CONFIG = {\n",
    "    'colors': {\n",
    "        'primary': '#2ecc71',    # Green for retained\n",
    "        'secondary': '#e74c3c',  # Red for churned\n",
    "        'neutral': '#3498db'     # Blue for general\n",
    "    },\n",
    "    'template': 'plotly_white',\n",
    "    'dimensions': {'width': 1000, 'height': 600}\n",
    "}\n",
    "\n",
    "class ChurnAnalyzer:\n",
    "    \"\"\"\n",
    "    A comprehensive analyzer for bank customer churn data.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, file_path: str):\n",
    "        \"\"\"Initialize the analyzer with data from file.\"\"\"\n",
    "        self.file_path = file_path\n",
    "        self.df = None\n",
    "        self.insights = {}\n",
    "        \n",
    "        # Load and validate data\n",
    "        self._load_data()\n",
    "    \n",
    "    def _load_data(self) -> None:\n",
    "        \"\"\"Load and validate the bank churn data.\"\"\"\n",
    "        try:\n",
    "            # File validation\n",
    "            file = Path(self.file_path)\n",
    "            if not file.exists():\n",
    "                raise FileNotFoundError(f\"File not found at: {self.file_path}\")\n",
    "            if file.suffix.lower() != '.csv':\n",
    "                raise ValueError(f\"File must be CSV, got: {file.suffix}\")\n",
    "            \n",
    "            # Load data\n",
    "            print(\"üìÇ Loading data...\")\n",
    "            self.df = pd.read_csv(file)\n",
    "            \n",
    "            # Validate columns\n",
    "            required_cols = {\n",
    "                'CustomerId', 'CreditScore', 'Geography', 'Gender',\n",
    "                'Age', 'Tenure', 'Balance', 'NumOfProducts',\n",
    "                'HasCrCard', 'IsActiveMember', 'EstimatedSalary', 'Exited'\n",
    "            }\n",
    "            missing_cols = required_cols - set(self.df.columns)\n",
    "            if missing_cols:\n",
    "                raise ValueError(f\"Missing columns: {missing_cols}\")\n",
    "            \n",
    "            print(f\"‚úÖ Loaded {len(self.df):,} records\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading data: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def analyze_demographics(self) -> Dict[str, Any]:\n",
    "        \"\"\"Analyze customer demographics.\"\"\"\n",
    "        print(\"\\nüîç Analyzing Demographics...\")\n",
    "        \n",
    "        demographics = {\n",
    "            'total_customers': len(self.df),\n",
    "            'churn_rate': self.df['Exited'].mean() * 100,\n",
    "            'age_stats': {\n",
    "                'mean': self.df['Age'].mean(),\n",
    "                'median': self.df['Age'].median(),\n",
    "                'std': self.df['Age'].std()\n",
    "            },\n",
    "            'balance_stats': {\n",
    "                'mean': self.df['Balance'].mean(),\n",
    "                'median': self.df['Balance'].median(),\n",
    "                'zero_balance_pct': (self.df['Balance'] == 0).mean() * 100\n",
    "            },\n",
    "            'geographic_dist': self.df['Geography'].value_counts(normalize=True).to_dict(),\n",
    "            'gender_dist': self.df['Gender'].value_counts(normalize=True).to_dict()\n",
    "        }\n",
    "        \n",
    "        # Visualize age distribution\n",
    "        fig = px.histogram(\n",
    "            self.df,\n",
    "            x='Age',\n",
    "            color='Exited',\n",
    "            marginal='box',\n",
    "            nbins=25,\n",
    "            title='Age Distribution by Churn Status',\n",
    "            color_discrete_map={\n",
    "                0: PLOT_CONFIG['colors']['primary'],\n",
    "                1: PLOT_CONFIG['colors']['secondary']\n",
    "            },\n",
    "            template=PLOT_CONFIG['template']\n",
    "        )\n",
    "        fig.show()\n",
    "        \n",
    "        self.insights['demographics'] = demographics\n",
    "        return demographics\n",
    "    \n",
    "    def analyze_geography(self) -> Dict[str, Any]:\n",
    "        \"\"\"Analyze geographic patterns.\"\"\"\n",
    "        print(\"\\nüåç Analyzing Geographic Patterns...\")\n",
    "        \n",
    "        geo_insights = {\n",
    "            'churn_by_country': self.df.groupby('Geography')['Exited'].mean().to_dict(),\n",
    "            'avg_balance': self.df.groupby('Geography')['Balance'].mean().to_dict(),\n",
    "            'avg_credit_score': self.df.groupby('Geography')['CreditScore'].mean().to_dict()\n",
    "        }\n",
    "        \n",
    "        # Visualize geographic churn rates\n",
    "        geo_data = pd.DataFrame(geo_insights['churn_by_country'].items(), \n",
    "                              columns=['Country', 'Churn_Rate'])\n",
    "        geo_data['Churn_Rate'] *= 100\n",
    "        \n",
    "        fig = px.bar(\n",
    "            geo_data,\n",
    "            x='Country',\n",
    "            y='Churn_Rate',\n",
    "            title='Churn Rate by Country',\n",
    "            color='Churn_Rate',\n",
    "            text='Churn_Rate',\n",
    "            template=PLOT_CONFIG['template']\n",
    "        )\n",
    "        fig.show()\n",
    "        \n",
    "        self.insights['geography'] = geo_insights\n",
    "        return geo_insights\n",
    "    \n",
    "    def build_predictive_model(self) -> Dict[str, Any]:\n",
    "        \"\"\"Build and evaluate a predictive model for churn.\"\"\"\n",
    "        print(\"\\nü§ñ Building Predictive Model...\")\n",
    "        \n",
    "        # Prepare features and target\n",
    "        features = [\n",
    "            'CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts',\n",
    "            'HasCrCard', 'IsActiveMember', 'Geography', 'Gender'\n",
    "        ]\n",
    "        X = self.df[features]\n",
    "        y = self.df['Exited']\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE\n",
    "        )\n",
    "        \n",
    "        # Create preprocessing pipeline\n",
    "        numeric_features = [\n",
    "            'CreditScore', 'Age', 'Tenure', 'Balance', \n",
    "            'NumOfProducts', 'HasCrCard', 'IsActiveMember'\n",
    "        ]\n",
    "        categorical_features = ['Geography', 'Gender']\n",
    "        \n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', StandardScaler(), numeric_features),\n",
    "                ('cat', OneHotEncoder(drop='first', sparse_output=False), \n",
    "                 categorical_features)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Create and train model\n",
    "        model = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', RandomForestClassifier(random_state=RANDOM_STATE))\n",
    "        ])\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluate model\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        model_insights = {\n",
    "            'roc_auc': roc_auc_score(y_test, y_pred_proba),\n",
    "            'classification_report': classification_report(y_test, y_pred, \n",
    "                                                        output_dict=True),\n",
    "            'feature_importance': dict(zip(features, \n",
    "                model.named_steps['classifier'].feature_importances_))\n",
    "        }\n",
    "        \n",
    "        # Visualize confusion matrix\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(\n",
    "            confusion_matrix(y_test, y_pred),\n",
    "            annot=True,\n",
    "            fmt='d',\n",
    "            cmap='Blues'\n",
    "        )\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.show()\n",
    "        \n",
    "        self.insights['model'] = model_insights\n",
    "        return model_insights\n",
    "    \n",
    "    def save_insights(self, output_path: str) -> None:\n",
    "        \"\"\"Save analysis insights to JSON file.\"\"\"\n",
    "        try:\n",
    "            with open(output_path, 'w') as f:\n",
    "                json.dump(self.insights, f, indent=4)\n",
    "            print(f\"\\n‚úÖ Insights saved to {output_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error saving insights: {str(e)}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution pipeline.\"\"\"\n",
    "    try:\n",
    "        # Initialize analyzer\n",
    "        analyzer = ChurnAnalyzer(\"Bank_Churn.csv\")\n",
    "        \n",
    "        # Run analyses\n",
    "        analyzer.analyze_demographics()\n",
    "        analyzer.analyze_geography()\n",
    "        analyzer.build_predictive_model()\n",
    "        \n",
    "        # Save results\n",
    "        analyzer.save_insights(\"churn_analysis_results.json\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Analysis failed: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
